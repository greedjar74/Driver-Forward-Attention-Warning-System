{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data ë¶„í• "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.png\n",
      "10.png\n",
      "100.png\n",
      "101.png\n",
      "102.png\n",
      "103.png\n",
      "104.png\n",
      "105.png\n",
      "106.png\n",
      "107.png\n",
      "108.png\n",
      "109.png\n",
      "11.png\n",
      "110.png\n",
      "111.png\n",
      "112.png\n",
      "113.png\n",
      "114.png\n",
      "115.png\n",
      "116.png\n",
      "117.png\n",
      "118.png\n",
      "119.png\n",
      "12.png\n",
      "120.png\n",
      "121.png\n",
      "122.png\n",
      "123.png\n",
      "124.png\n",
      "125.png\n",
      "126.png\n",
      "127.png\n",
      "128.png\n",
      "129.png\n",
      "13.png\n",
      "130.png\n",
      "131.png\n",
      "132.png\n",
      "133.png\n",
      "134.png\n",
      "135.png\n",
      "136.png\n",
      "137.png\n",
      "138.png\n",
      "139.png\n",
      "14.png\n",
      "140.png\n",
      "141.png\n",
      "142.png\n",
      "143.png\n",
      "144.png\n",
      "145.png\n",
      "146.png\n",
      "147.png\n",
      "148.png\n",
      "149.png\n",
      "15.png\n",
      "150.png\n",
      "151.png\n",
      "152.png\n",
      "153.png\n",
      "154.png\n",
      "155.png\n",
      "156.png\n",
      "157.png\n",
      "158.png\n",
      "159.png\n",
      "16.png\n",
      "17.png\n",
      "18.png\n",
      "19.png\n",
      "2.png\n",
      "20.png\n",
      "21.png\n",
      "22.png\n",
      "23.png\n",
      "24.png\n",
      "25.png\n",
      "26.png\n",
      "27.png\n",
      "28.png\n",
      "29.png\n",
      "3.png\n",
      "30.png\n",
      "31.png\n",
      "32.png\n",
      "33.png\n",
      "34.png\n",
      "35.png\n",
      "36.png\n",
      "37.png\n",
      "38.png\n",
      "39.png\n",
      "4.png\n",
      "40.png\n",
      "41.png\n",
      "42.png\n",
      "43.png\n",
      "44.png\n",
      "45.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "image_root = '/Volumes/samsung ssd/4í•™ë…„1í•™ê¸°/ë…¼ë¬¸/data/image'\n",
    "label_root = '/Volumes/samsung ssd/4í•™ë…„1í•™ê¸°/ë…¼ë¬¸/data/label'\n",
    "\n",
    "image_list = os.listdir('/Volumes/samsung ssd/4í•™ë…„1í•™ê¸°/ë…¼ë¬¸/data/image')\n",
    "label_list = os.listdir('/Volumes/samsung ssd/4í•™ë…„1í•™ê¸°/ë…¼ë¬¸/data/label')\n",
    "\n",
    "image_list.sort()\n",
    "label_list.sort()\n",
    "\n",
    "for i in range(100):\n",
    "    img = image_list[i]\n",
    "    print(img)\n",
    "    shutil.copyfile(os.path.join(image_root, img), os.path.join('/Volumes/samsung ssd/4í•™ë…„1í•™ê¸°/ë…¼ë¬¸/YOLOv8/data/train/images', img))\n",
    "    shutil.copyfile(os.path.join(label_root, img.replace('png', 'txt')), os.path.join('/Volumes/samsung ssd/4í•™ë…„1í•™ê¸°/ë…¼ë¬¸/YOLOv8/data/train/labels', img.replace('png', 'txt')))\n",
    "\n",
    "for i in range(100, 150):\n",
    "    img = image_list[i]\n",
    "    shutil.copyfile(os.path.join(image_root, img), os.path.join('/Volumes/samsung ssd/4í•™ë…„1í•™ê¸°/ë…¼ë¬¸/YOLOv8/data/valid/images', img))\n",
    "    shutil.copyfile(os.path.join(label_root, img.replace('png', 'txt')), os.path.join('/Volumes/samsung ssd/4í•™ë…„1í•™ê¸°/ë…¼ë¬¸/YOLOv8/data/valid/labels', img.replace('png', 'txt')))\n",
    "\n",
    "for i in range(150, len(image_list)):\n",
    "    img = image_list[i]\n",
    "    shutil.copyfile(os.path.join(image_root, img), os.path.join('/Volumes/samsung ssd/4í•™ë…„1í•™ê¸°/ë…¼ë¬¸/YOLOv8/data/test/images', img))\n",
    "    shutil.copyfile(os.path.join(label_root, img.replace('png', 'txt')), os.path.join('/Volumes/samsung ssd/4í•™ë…„1í•™ê¸°/ë…¼ë¬¸/YOLOv8/data/test/labels', img.replace('png', 'txt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "pjt_root = '/Volumes/samsung ssd/4í•™ë…„1í•™ê¸°/ë…¼ë¬¸/YOLOv8'\n",
    "classes = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'eye']\n",
    "\n",
    "data = dict()\n",
    "data['train'] = '/Volumes/samsung ssd/4í•™ë…„1í•™ê¸°/ë…¼ë¬¸/YOLOv8/data/train'\n",
    "data['val'] = '/Volumes/samsung ssd/4í•™ë…„1í•™ê¸°/ë…¼ë¬¸/YOLOv8/data/valid'\n",
    "data['test'] = '/Volumes/samsung ssd/4í•™ë…„1í•™ê¸°/ë…¼ë¬¸/YOLOv8/data/test'\n",
    "data['nc'] = len(classes)\n",
    "data['names'] = classes\n",
    "\n",
    "with open(f'{pjt_root}/eye_detect.yaml', 'w') as f:\n",
    "    yaml.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.75 ðŸš€ Python-3.11.7 torch-2.4.0 CPU (Apple M1 Pro)\n",
      "Setup complete âœ… (10 CPUs, 16.0 GB RAM, 435.6/460.4 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/samsung ssd/4á„’á…¡á†¨á„‚á…§á†«1á„’á…¡á†¨á„€á…µ/á„‚á…©á†«á„†á…®á†«/YOLOv8\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "%cd /Volumes/samsung ssd/4í•™ë…„1í•™ê¸°/ë…¼ë¬¸/YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21.5M/21.5M [00:02<00:00, 10.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.75 ðŸš€ Python-3.11.7 torch-2.4.0 CPU (Apple M1 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=eye_detect.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=384, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/opt/homebrew/runs/detect/train\n",
      "Overriding model.yaml nc=80 with nc=16\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2122240  ultralytics.nn.modules.head.Detect           [16, [128, 256, 512]]         \n",
      "Model summary: 225 layers, 11,141,792 parameters, 11,141,776 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /opt/homebrew/runs/detect/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Volumes/samsung ssd/4í•™ë…„1í•™ê¸°/ë…¼ë¬¸/YOLOv8/data/train/labels... 100 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 112.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Volumes/samsung ssd/4í•™ë…„1í•™ê¸°/ë…¼ë¬¸/YOLOv8/data/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Volumes/samsung ssd/4í•™ë…„1í•™ê¸°/ë…¼ë¬¸/YOLOv8/data/valid/labels... 50 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:01<00:00, 36.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Volumes/samsung ssd/4í•™ë…„1í•™ê¸°/ë…¼ë¬¸/YOLOv8/data/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /opt/homebrew/runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 384 train, 384 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/opt/homebrew/runs/detect/train\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1         0G      2.236      10.69      1.267         16        384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:33<00:00,  4.85s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         50        181          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from /opt/homebrew/runs/detect/train/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from /opt/homebrew/runs/detect/train/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating /opt/homebrew/runs/detect/train/weights/best.pt...\n",
      "Ultralytics 8.3.75 ðŸš€ Python-3.11.7 torch-2.4.0 CPU (Apple M1 Pro)\n",
      "Model summary (fused): 168 layers, 11,131,776 parameters, 0 gradients, 28.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:15<00:00,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         50        181          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.5ms preprocess, 144.8ms inference, 0.0ms loss, 12.5ms postprocess per image\n",
      "Results saved to \u001b[1m/opt/homebrew/runs/detect/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8s.pt')\n",
    "results = model.train(data='eye_detect.yaml', epochs=1, batch=16, imgsz=384)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "test_image_list = glob.glob('/Volumes/samsung ssd/4í•™ë…„1í•™ê¸°/ë…¼ë¬¸/YOLOv8/data/test/images/*')\n",
    "len(test_image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 224x224 3 eyes, 23.8ms\n",
      "Speed: 0.0ms preprocess, 23.8ms inference, 0.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'eye'}\n",
      "obb: None\n",
      "orig_img: array([[[179, 231, 159],\n",
      "        [165, 212, 147],\n",
      "        [ 78, 110,  69],\n",
      "        ...,\n",
      "        [103,  68,  45],\n",
      "        [108,  72,  49],\n",
      "        [111,  76,  54]],\n",
      "\n",
      "       [[169, 224, 152],\n",
      "        [177, 228, 159],\n",
      "        [119, 153, 104],\n",
      "        ...,\n",
      "        [ 80,  55,  43],\n",
      "        [104,  73,  52],\n",
      "        [112,  80,  59]],\n",
      "\n",
      "       [[140, 190, 126],\n",
      "        [148, 193, 129],\n",
      "        [ 96, 123,  82],\n",
      "        ...,\n",
      "        [ 64,  43,  39],\n",
      "        [ 93,  68,  55],\n",
      "        [100,  76,  62]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 98,  88,  78],\n",
      "        [105,  98,  91],\n",
      "        [105,  98,  91],\n",
      "        ...,\n",
      "        [ 32,  28,  22],\n",
      "        [ 30,  26,  19],\n",
      "        [ 27,  24,  17]],\n",
      "\n",
      "       [[ 80,  72,  67],\n",
      "        [110, 104,  98],\n",
      "        [101,  94,  90],\n",
      "        ...,\n",
      "        [ 32,  28,  19],\n",
      "        [ 32,  28,  20],\n",
      "        [ 31,  28,  20]],\n",
      "\n",
      "       [[ 97,  90,  87],\n",
      "        [115, 109, 104],\n",
      "        [ 85,  78,  76],\n",
      "        ...,\n",
      "        [ 72,  65,  48],\n",
      "        [ 66,  59,  48],\n",
      "        [ 62,  56,  47]]], dtype=uint8)\n",
      "orig_shape: (224, 224)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: '/opt/homebrew/runs/detect/predict'\n",
      "speed: {'preprocess': 0.00700005330145359, 'inference': 23.790542036294937, 'postprocess': 0.4351249663159251}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m re \u001b[38;5;241m=\u001b[39m model(x_tensor)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(re)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28mprint\u001b[39m(re\u001b[38;5;241m.\u001b[39mprobs\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m     26\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(img)\n\u001b[1;32m     27\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses[torch\u001b[38;5;241m.\u001b[39margmax(re\u001b[38;5;241m.\u001b[39mprobs\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;241m.\u001b[39mitem()]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'data'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('/Volumes/samsung ssd/4í•™ë…„1í•™ê¸°/ë…¼ë¬¸/YOLOv8/weights/best.pt')\n",
    "transforms = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "classes = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'eye']\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    img = Image.open(test_image_list[i]).convert(\"RGB\")\n",
    "    img_src = transforms(img)\n",
    "    x_tensor = img_src.unsqueeze(0)\n",
    "    re = model(x_tensor)[0]\n",
    "    print(re)\n",
    "    print(re.probs.data)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Pred: {classes[torch.argmax(re.probs.data).item()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
